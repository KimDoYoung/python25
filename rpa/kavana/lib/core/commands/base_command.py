from abc import ABC, abstractmethod
import copy
from typing import List

from lib.core.exceptions.kavana_exception import KavanaSyntaxError, KavanaValueError
from lib.core.expr_evaluator import ExprEvaluator
from lib.core.token import ArrayToken, HashMapToken, Token
from lib.core.token_type import TokenType
from lib.core.token_util import TokenUtil

class BaseCommand(ABC):
    """
    ëª¨ë“  ëª…ë ¹ì–´(Command) í´ë˜ìŠ¤ê°€ ìƒì†í•´ì•¼ í•˜ëŠ” ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤
    """
    @abstractmethod
    def execute(self, args, executor):
        pass

    def count_express(self, tokens: List[Token]) -> int:
            """
            tokens ë¦¬ìŠ¤íŠ¸ì—ì„œ ','(COMMA)ì˜ ê°œìˆ˜ë¥¼ ì„¸ê³ , ê´„í˜¸ë‚˜ ëŒ€ê´„í˜¸ ì•ˆì— ìˆëŠ” ê²½ìš° ì œì™¸.
            - ê´„í˜¸ ë‚´ë¶€ì˜ ','ëŠ” ë¬´ì‹œí•¨.
            - ','ê°€ ì—†ìœ¼ë©´ 1ì„ ë°˜í™˜, ìˆìœ¼ë©´ ',' ê°œìˆ˜ + 1ì„ ë°˜í™˜.
            """
            count = 0
            paren_depth = 0  # ê´„í˜¸ ê¹Šì´ í™•ì¸
            bracket_depth = 0  # ëŒ€ê´„í˜¸ ê¹Šì´ í™•ì¸
            
            for token in tokens:
                if token.type == TokenType.LEFT_PAREN:
                    paren_depth += 1
                elif token.type == TokenType.RIGHT_PAREN:
                    paren_depth -= 1
                elif token.type == TokenType.LEFT_BRACKET:
                    bracket_depth += 1
                elif token.type == TokenType.RIGHT_BRACKET:
                    bracket_depth -= 1
                elif token.type == TokenType.COMMA and paren_depth == 0 and bracket_depth == 0:
                    count += 1
            
            return count + 1 if count > 0 else 1

    def is_key_exists(self, tokens: List[Token], key: str) -> bool:
        """
        tokens ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • keyê°€ '=' (ASSIGN) ì™¼ìª½ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸.
        - ê´„í˜¸ ()ë‚˜ ëŒ€ê´„í˜¸ [] ì•ˆì— ìˆëŠ” ê²½ìš° ì œì™¸.
        - keyê°€ ì¡´ì¬í•˜ë©´ True, ì—†ìœ¼ë©´ False ë°˜í™˜.
        """
        paren_depth = 0  # ê´„í˜¸ ê¹Šì´
        bracket_depth = 0  # ëŒ€ê´„í˜¸ ê¹Šì´
        
        for i in range(1, len(tokens)):
            token = tokens[i]
            
            if token.type == TokenType.LEFT_PAREN:
                paren_depth += 1
            elif token.type == TokenType.RIGHT_PAREN:
                paren_depth -= 1
            elif token.type == TokenType.LEFT_BRACKET:
                bracket_depth += 1
            elif token.type == TokenType.RIGHT_BRACKET:
                bracket_depth -= 1
            
            if token.type == TokenType.ASSIGN and paren_depth == 0 and bracket_depth == 0:
                prev_token = tokens[i - 1]
                if prev_token.type == TokenType.IDENTIFIER and prev_token.data.string == key:
                    return True
        
        return False    
    
    def get_express(self, tokens, start_idx):
        """
        ì£¼ì–´ì§„ tokensì—ì„œ start_idxë¶€í„° ì‹œì‘í•˜ì—¬ ',' ë˜ëŠ” ëê¹Œì§€ í‘œí˜„ì‹ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
        ê´„í˜¸ (), ëŒ€ê´„í˜¸ [] ê¹Šì´ë¥¼ ê³ ë ¤í•˜ì—¬ ì˜¬ë°”ë¥´ê²Œ í‘œí˜„ì‹ì„ ë¶„ë¦¬í•¨.
        """
        if start_idx >= len(tokens):
            return start_idx, []
        
        expresses = []
        paren_depth = 0  # ê´„í˜¸ ê¹Šì´
        bracket_depth = 0  # ëŒ€ê´„í˜¸ ê¹Šì´
        
        i = start_idx
        while tokens[i].type == TokenType.COMMA:
            i += 1

        while i < len(tokens):
            token = tokens[i]
            if token.type == TokenType.LEFT_PAREN:
                paren_depth += 1
            elif token.type == TokenType.RIGHT_PAREN:
                paren_depth -= 1
            elif token.type == TokenType.LEFT_BRACKET:
                bracket_depth += 1
            elif token.type == TokenType.RIGHT_BRACKET:
                bracket_depth -= 1
            elif token.type == TokenType.COMMA and paren_depth == 0 and bracket_depth == 0:
                return i + 1, expresses  # ','ë¥¼ ë§Œë‚˜ë©´ í‘œí˜„ì‹ ì¢…ë£Œ
            
            expresses.append(token)
            i += 1
        
        return expresses, i
    
    def extract_all_options0(self, tokens: List[Token], start_idx: int):
        """
        ì£¼ì–´ì§„ tokens ë¦¬ìŠ¤íŠ¸ì—ì„œ key=value ì˜µì…˜ì„ ëª¨ë‘ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
        - keyëŠ” IDENTIFIER
        - '=' ì—°ì‚°ìê°€ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨
        - valueëŠ” ',' ë˜ëŠ” tokens ëê¹Œì§€ í‘œí˜„ì‹ì„ í¬í•¨
        {
            "limit": {
                "key_token": Token(IDENTIFIER, 'limit'),
                "express": [Token(INTEGER, '100')]
            },
            "offset": {
                "key_token": Token(IDENTIFIER, 'offset'),
                "express": [Token(INTEGER, '20')]
            }
        }        
        """
        options = {}
        i = start_idx
        
        while i < len(tokens):
            key_token, express_tokens, next_index = self.extract_option1(tokens, i)
            if key_token is None:
                break
            key = key_token.data.string.strip().lower()
            options[key] = {"key_token": key_token, "express": express_tokens}
            i = next_index
        
        return options, i    
    
    def extract_all_options(self, tokens: List[Token], start_idx: int):
        """
        ì£¼ì–´ì§„ tokens ë¦¬ìŠ¤íŠ¸ì—ì„œ key=value ì˜µì…˜ì„ ëª¨ë‘ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
        key=value ì˜µì…˜ë“¤ì„ ',' ì—†ì´ë„ ì—°ì†ì ìœ¼ë¡œ ì¶”ì¶œ
        ë‹¤ìŒ í† í°ì´ IDENTIFIER, ê·¸ ë‹¤ìŒì´ ASSIGN(=)ì´ë©´ ìƒˆë¡œìš´ ì˜µì…˜ìœ¼ë¡œ ê°„ì£¼
        """
        options = {}
        i = start_idx

        while i < len(tokens):
            key_token, express_tokens, next_index = self.extract_option1(tokens, i)
            if key_token is None:
                break

            key = key_token.data.string.strip().lower()
            options[key] = {"key_token": key_token, "express": express_tokens}
            i = next_index

            # ê¸°ì¡´ì—ëŠ” ì—¬ê¸°ì„œ ë¬´ì¡°ê±´ ','ë¥¼ ê¸°ëŒ€í–ˆìŒ
            # ì´ì œëŠ” ë‹¤ìŒ í† í°ì´ IDENTIFIERì´ê³ , ê·¸ ë‹¤ìŒì´ '='ì´ë©´ ìƒˆë¡œìš´ ì˜µì…˜ìœ¼ë¡œ ê°„ì£¼
            if i + 1 < len(tokens):
                next_token = tokens[i]
                next_next_token = tokens[i + 1]

                if next_token.type == TokenType.IDENTIFIER and next_next_token.type == TokenType.ASSIGN:
                    continue  # ',' ì—†ì´ë„ ë‹¤ìŒ ì˜µì…˜ìœ¼ë¡œ ì¸ì‹ â†’ ë£¨í”„ ìœ ì§€
                elif next_token.type == TokenType.COMMA:
                    i += 1  # ',' ê±´ë„ˆë›°ê³  ë‹¤ìŒ ì˜µì…˜ìœ¼ë¡œ
                    continue

            break  # ë‹¤ìŒì— IDENTIFIER= ê°€ ì—†ìœ¼ë©´ ì˜µì…˜ ì¶”ì¶œ ì¢…ë£Œ

        return options, i


    def extract_option1(self, tokens: list[Token], start_index: int) -> tuple[Token, List[Token], int]:
        """
        - key=express íŒŒì‹±
        - ê´„í˜¸ ì•ˆì˜ =, , ëŠ” ë¬´ì‹œ
        - keyëŠ” = ì•ì˜ í† í°
        - expressëŠ” = ë’¤ë¶€í„° ê´„í˜¸ ê³ ë ¤í•´ì„œ ',' ë˜ëŠ” ë‹¤ìŒ IDENTIFIER= ë˜ëŠ” ëê¹Œì§€
        """
        if start_index >= len(tokens):
            return None, None, start_index

        # ê´„í˜¸ ìŠ¤íƒì„ ì‚¬ìš©í•´ ì¤‘ì²© ì¶”ì 
        bracket_stack = []
        assign_index = -1
        i = start_index

        # 1. ASSIGN(=) í† í° ì°¾ê¸° (ê´„í˜¸ ë°–ì—ì„œ)
        while i < len(tokens):
            token = tokens[i]

            if token.type in (TokenType.LEFT_PAREN, TokenType.LEFT_BRACKET):
                bracket_stack.append(token.type)
            elif token.type == TokenType.RIGHT_PAREN:
                if bracket_stack and bracket_stack[-1] == TokenType.LEFT_PAREN:
                    bracket_stack.pop()
                else:
                    raise KavanaSyntaxError("ê´„í˜¸ '(' ì™€ ')'ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            elif token.type == TokenType.RIGHT_BRACKET:
                if bracket_stack and bracket_stack[-1] == TokenType.LEFT_BRACKET:
                    bracket_stack.pop()
                else:
                    raise KavanaSyntaxError("ê´„í˜¸ '[' ì™€ ']'ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            elif token.type == TokenType.ASSIGN and not bracket_stack:
                assign_index = i
                break

            i += 1

        if assign_index == -1:
            raise KavanaSyntaxError("ì˜µì…˜ì— '=' ì—°ì‚°ìê°€ ì—†ìŠµë‹ˆë‹¤.")

        if assign_index == start_index:
            raise KavanaSyntaxError("'=' ì•ì— key í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")

        key_token = tokens[assign_index - 1]
        if key_token.type != TokenType.IDENTIFIER:
            raise KavanaSyntaxError("ì˜µì…˜ì˜ keyëŠ” IDENTIFIER íƒ€ì…ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

        # 2. express ìˆ˜ì§‘ (ê´„í˜¸ ì•ˆì˜ , ëŠ” ë¬´ì‹œ)
        expresses = []
        i = assign_index + 1
        bracket_stack.clear()

        while i < len(tokens):
            token = tokens[i]

            if token.type in (TokenType.LEFT_PAREN, TokenType.LEFT_BRACKET):
                bracket_stack.append(token.type)
            elif token.type == TokenType.RIGHT_PAREN:
                if bracket_stack and bracket_stack[-1] == TokenType.LEFT_PAREN:
                    bracket_stack.pop()
                else:
                    raise KavanaSyntaxError("ê´„í˜¸ '(' ì™€ ')'ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            elif token.type == TokenType.RIGHT_BRACKET:
                if bracket_stack and bracket_stack[-1] == TokenType.LEFT_BRACKET:
                    bracket_stack.pop()
                else:
                    raise KavanaSyntaxError("ê´„í˜¸ '[' ì™€ ']'ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # âœ… ì¢…ë£Œ ì¡°ê±´ 1: ê´„í˜¸ ë°–ì—ì„œ ',' ë§Œë‚˜ë©´ express ì¢…ë£Œ
            if token.type == TokenType.COMMA and not bracket_stack:
                i += 1
                break

            # âœ… ì¢…ë£Œ ì¡°ê±´ 2: ê´„í˜¸ ë°–ì—ì„œ ë‹¤ìŒ í† í°ì´ IDENTIFIER = í˜•íƒœì´ë©´ express ì¢…ë£Œ
            if not bracket_stack and i + 1 < len(tokens):
                next_token = tokens[i]
                next_next_token = tokens[i + 1]
                if next_token.type == TokenType.IDENTIFIER and next_next_token.type == TokenType.ASSIGN:
                    break

            expresses.append(token)
            i += 1

        if not expresses:
            raise KavanaSyntaxError(f"ì˜µì…˜ '{key_token.data.string}'ì˜ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")

        return key_token, expresses, i

    def hashmap_token_to_dict(self, token: Token, executor) -> dict:
        """HashMapTokenì„ dictë¡œ ë³€í™˜"""
        if not isinstance(token, Token) or token.type != TokenType.HASH_MAP:
            raise KavanaSyntaxError("HashMapTokenì´ ì•„ë‹™ë‹ˆë‹¤.")
        
        result = {}
        for key, express in token.key_express_map.items():
            if not isinstance(key, str):
                raise KavanaSyntaxError(f"ì˜ëª»ëœ í‚¤ íƒ€ì…: {key} ({type(key)})")
            token = ExprEvaluator(executor=executor).evaluate(express)
            if token.type == TokenType.HASH_MAP:
                result[key] = self.hashmap_token_to_dict(token, executor)
            elif token.type == TokenType.ARRAY:
                result[key] = self.array_token_to_list(token, executor)
            else:
                result[key] = token.data.value
            # if isinstance(result[key], HashMapToken):
            #     result[key] = self.hashmap_token_to_dict(result[key], executor)
            # elif isinstance(result[key], ArrayToken):
            #     result[key] = self.array_token_to_list(result[key], executor)
                
        return result
    
    def array_token_to_list(self, token: Token, executor) -> list:
        """ArrayTokenì„ listë¡œ ë³€í™˜"""
        if not isinstance(token, Token) or token.type != TokenType.ARRAY:
            raise KavanaSyntaxError("ArrayTokenì´ ì•„ë‹™ë‹ˆë‹¤.")
        
        result = []
        for express in token.element_expresses:
            result.append(ExprEvaluator(executor=executor).evaluate(express).data.value)
        return result
    

    def parse_and_validate_options(self, options: dict, option_map: dict, executor) -> dict:
        """
        ì£¼ì–´ì§„ optionsë¥¼ option_map ê¸°ì¤€ìœ¼ë¡œ ê²€ì¦í•˜ê³  ìµœì¢… ê°’ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬í„´í•œë‹¤.
        - íƒ€ì… ì²´í¬, required ì²´í¬, default ì ìš© í¬í•¨
        - min/max, choices ê²€ì¦ ì¶”ê°€
        """
        option_values = {}

        # 1. 'with=' ë³‘í•© ì²˜ë¦¬
        if 'with' in options:
            var_name_express = options['with']["express"]
            hashmap_token = ExprEvaluator(executor=executor).evaluate(var_name_express)
            with_values = self.hashmap_token_to_dict(hashmap_token, executor)
            option_values.update(with_values)
            del options['with']

        # 2. ê°œë³„ ì˜µì…˜ í‰ê°€ ë° íƒ€ì… ì²´í¬
        for key, value_dict in options.items():
            if key not in option_map:
                raise KavanaSyntaxError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: '{key}'")

            opt = option_map[key]
            value_express = value_dict["express"]
            evaluated = ExprEvaluator(executor=executor).evaluate(value_express)

            allowed_types = opt.get("allowed_types", [])
            if evaluated.type not in allowed_types:
                raise KavanaSyntaxError(
                    f"ì˜µì…˜ '{key}'ì˜ íƒ€ì…ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                    f"í—ˆìš©ëœ íƒ€ì…: {', '.join(t.name for t in allowed_types)}, "
                    f"ì‹¤ì œ íƒ€ì…: {evaluated.type.name}"
                )

            if evaluated.type == TokenType.HASH_MAP:
                option_values[key] = self.hashmap_token_to_dict(evaluated, executor)
            elif evaluated.type == TokenType.ARRAY:
                option_values[key] = self.array_token_to_list(evaluated, executor)
            else:
                option_values[key] = evaluated.data.value

            # ğŸ” ê°’ ë²”ìœ„ ì²´í¬ (min/max)
            if "min" in opt and option_values[key] < opt["min"]:
                raise KavanaSyntaxError(f"ì˜µì…˜ '{key}' ê°’ì€ ìµœì†Œ {opt['min']} ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            if "max" in opt and option_values[key] > opt["max"]:
                raise KavanaSyntaxError(f"ì˜µì…˜ '{key}' ê°’ì€ ìµœëŒ€ {opt['max']} ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

            # ğŸ” choices ì²´í¬ (ì—´ê±°í˜• ì œí•œ)
            if "choices" in opt and option_values[key] not in opt["choices"]:
                raise KavanaSyntaxError(
                    f"ì˜µì…˜ '{key}' ê°’ì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤: "
                    f"{', '.join(str(c) for c in opt['choices'])} "
                    f"(í˜„ì¬ ê°’: {option_values[key]})"
                )

        # 3. í•„ìˆ˜ ì˜µì…˜ ëˆ„ë½ ì²´í¬
        for key, opt in option_map.items():
            if opt.get("required", False) and key not in option_values:
                raise KavanaSyntaxError(f"í•„ìˆ˜ ì˜µì…˜ '{key}'ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # 4. ê¸°ë³¸ê°’ ì ìš©
        for key, opt in option_map.items():
            if key not in option_values and "default" in opt:
                option_values[key] = opt["default"]

        return option_values


    def check_option_rules(self, subcommand: str, params: dict):
        ''' OPTION_RULESì— ì •ì˜ëœ ê·œì¹™ì„ ì²´í¬í•œë‹¤.'''
        rules = getattr(self, "OPTION_RULES", {}).get(subcommand, {})

        # 1. ìƒí˜¸ ë°°íƒ€ (mutually exclusive)
        for group in rules.get("mutually_exclusive", []):
            present = [key for key in group if key in params]
            if len(present) > 1:
                raise KavanaValueError(f"{subcommand} ì˜µì…˜ ì¶©ëŒ: {', '.join(present)} ëŠ” ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. í•¨ê»˜ ìˆì–´ì•¼ í•¨ (required together)
        for group in rules.get("required_together", []):
            present = [key for key in group if key in params]
            if 0 < len(present) < len(group):
                missing = [key for key in group if key not in params]
                raise KavanaValueError(f"{subcommand} ì˜µì…˜ ë¶€ì¡±: {', '.join(group)} ëŠ” í•¨ê»˜ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤. ëˆ„ë½: {', '.join(missing)}")



    def _resolve_option_definitions(
        self,
        option_keys: list[str],
        base_definitions: dict,
        overrides: dict = None
    ) -> dict:
        if overrides is None:
            overrides = {}

        resolved = {}
        for key in option_keys:
            if key not in base_definitions:
                raise ValueError(f"ì •ì˜ë˜ì§€ ì•Šì€ ì˜µì…˜ í‚¤: {key}")
            base = copy.deepcopy(base_definitions[key])
            override = overrides.get(key, {})
            resolved[key] = {**base, **override}
        return resolved

    def get_option_definitions(self, sub_command: str) -> dict:
        """
        COMMAND_OPTION_MAPê³¼ OPTION_DEFINITIONSë¥¼ ê¸°ë°˜ìœ¼ë¡œ
        ëª…ë ¹ì–´ë³„ ìµœì¢… ì˜µì…˜ ì •ì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜
        """
        config = self.COMMAND_OPTION_MAP.get(sub_command)
        if not config:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” sub_command: {sub_command}")

        keys = config.get("keys", [])
        overrides = config.get("overrides", {})
        return self._resolve_option_definitions(keys, self.OPTION_DEFINITIONS, overrides)
